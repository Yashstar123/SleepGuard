{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f5bf25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\spars\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp # Import mediapipe\n",
    "import cv2 # Import opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6799d762",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils # Drawing helpers\n",
    "mp_holistic = mp.solutions.holistic # Mediapipe Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa320a5",
   "metadata": {},
   "source": [
    "# detection of landmarks using mediapipe hollistic the landmarks involves facial landmarks, hand landmarks and pose landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d6f3925",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Initiate holistic model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor Feed\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False        \n",
    "        \n",
    "        # Make Detections\n",
    "        results = holistic.process(image)\n",
    "        # print(results.face_landmarks)\n",
    "        \n",
    "        # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "        # Recolor image back to BGR for rendering\n",
    "        image.flags.writeable = True   \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Draw face landmarks\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "         # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "                        \n",
    "        cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e9c12b",
   "metadata": {},
   "source": [
    "# result of face landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a5c8bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[x: 0.6388727\n",
       "y: 0.75144553\n",
       "z: -0.02020229\n",
       ", x: 0.63857764\n",
       "y: 0.7026685\n",
       "z: -0.06061354\n",
       ", x: 0.6365638\n",
       "y: 0.7132991\n",
       "z: -0.026330762\n",
       ", x: 0.6230809\n",
       "y: 0.6491208\n",
       "z: -0.055548552\n",
       ", x: 0.6380318\n",
       "y: 0.68777335\n",
       "z: -0.06720114\n",
       ", x: 0.63604754\n",
       "y: 0.66560763\n",
       "z: -0.06628079\n",
       ", x: 0.6298515\n",
       "y: 0.6080942\n",
       "z: -0.045911115\n",
       ", x: 0.5371004\n",
       "y: 0.60338193\n",
       "z: -0.008000541\n",
       ", x: 0.62684685\n",
       "y: 0.56883985\n",
       "z: -0.04641508\n",
       ", x: 0.62589055\n",
       "y: 0.547831\n",
       "z: -0.053834293\n",
       ", x: 0.620096\n",
       "y: 0.4613952\n",
       "z: -0.058026034\n",
       ", x: 0.6391585\n",
       "y: 0.7591449\n",
       "z: -0.017004544\n",
       ", x: 0.6389552\n",
       "y: 0.7642282\n",
       "z: -0.011835047\n",
       ", x: 0.63840276\n",
       "y: 0.76540923\n",
       "z: -0.0056269667\n",
       ", x: 0.6387305\n",
       "y: 0.767293\n",
       "z: -0.0013537473\n",
       ", x: 0.63937896\n",
       "y: 0.77458715\n",
       "z: -0.0019916848\n",
       ", x: 0.63987464\n",
       "y: 0.7832372\n",
       "z: -0.002923578\n",
       ", x: 0.6399428\n",
       "y: 0.791595\n",
       "z: 0.0006381367\n",
       ", x: 0.63898844\n",
       "y: 0.80103385\n",
       "z: 0.014573802\n",
       ", x: 0.6381482\n",
       "y: 0.70871586\n",
       "z: -0.053216077\n",
       ", x: 0.6248301\n",
       "y: 0.7065874\n",
       "z: -0.03714045\n",
       ", x: 0.48531014\n",
       "y: 0.5339505\n",
       "z: 0.02800708\n",
       ", x: 0.57530236\n",
       "y: 0.61376345\n",
       "z: -0.014950046\n",
       ", x: 0.5633729\n",
       "y: 0.616578\n",
       "z: -0.014964501\n",
       ", x: 0.5511006\n",
       "y: 0.61724496\n",
       "z: -0.012885622\n",
       ", x: 0.5330359\n",
       "y: 0.6081133\n",
       "z: -0.0054100365\n",
       ", x: 0.58475167\n",
       "y: 0.6088987\n",
       "z: -0.013332287\n",
       ", x: 0.5535795\n",
       "y: 0.57901716\n",
       "z: -0.02726779\n",
       ", x: 0.5670314\n",
       "y: 0.5788977\n",
       "z: -0.026183564\n",
       ", x: 0.54141736\n",
       "y: 0.581655\n",
       "z: -0.02382463\n",
       ", x: 0.53357136\n",
       "y: 0.58651495\n",
       "z: -0.01880513\n",
       ", x: 0.5246387\n",
       "y: 0.6182935\n",
       "z: 0.0016993997\n",
       ", x: 0.59488803\n",
       "y: 0.82175994\n",
       "z: 0.031556435\n",
       ", x: 0.53153867\n",
       "y: 0.59912276\n",
       "z: -0.005315023\n",
       ", x: 0.48662585\n",
       "y: 0.602893\n",
       "z: 0.048629716\n",
       ", x: 0.50917214\n",
       "y: 0.60642904\n",
       "z: 0.009896094\n",
       ", x: 0.57132673\n",
       "y: 0.6835973\n",
       "z: -0.011355749\n",
       ", x: 0.62329066\n",
       "y: 0.7502256\n",
       "z: -0.020309567\n",
       ", x: 0.6258107\n",
       "y: 0.76512635\n",
       "z: -0.011206441\n",
       ", x: 0.607397\n",
       "y: 0.7554656\n",
       "z: -0.013695499\n",
       ", x: 0.59758586\n",
       "y: 0.7605683\n",
       "z: -0.0047220183\n",
       ", x: 0.61406225\n",
       "y: 0.7660232\n",
       "z: -0.007618704\n",
       ", x: 0.60502\n",
       "y: 0.7667818\n",
       "z: 0.00019955343\n",
       ", x: 0.58171934\n",
       "y: 0.7796317\n",
       "z: 0.019416416\n",
       ", x: 0.6280923\n",
       "y: 0.7029472\n",
       "z: -0.06036792\n",
       ", x: 0.62570775\n",
       "y: 0.6889604\n",
       "z: -0.06672805\n",
       ", x: 0.5129792\n",
       "y: 0.5697092\n",
       "z: -0.021598961\n",
       ", x: 0.5923365\n",
       "y: 0.64109164\n",
       "z: -0.020122876\n",
       ", x: 0.59477025\n",
       "y: 0.69589275\n",
       "z: -0.0338449\n",
       ", x: 0.59291285\n",
       "y: 0.686598\n",
       "z: -0.031614196\n",
       ", x: 0.5355868\n",
       "y: 0.6819626\n",
       "z: -0.0002462283\n",
       ", x: 0.624408\n",
       "y: 0.66797894\n",
       "z: -0.06344089\n",
       ", x: 0.5417776\n",
       "y: 0.55606246\n",
       "z: -0.04203872\n",
       ", x: 0.5244011\n",
       "y: 0.5603076\n",
       "z: -0.033767648\n",
       ", x: 0.49524808\n",
       "y: 0.5091162\n",
       "z: -7.323504e-05\n",
       ", x: 0.5989403\n",
       "y: 0.5678126\n",
       "z: -0.04557598\n",
       ", x: 0.57896304\n",
       "y: 0.58225685\n",
       "z: -0.020911966\n",
       ", x: 0.5720085\n",
       "y: 0.7668941\n",
       "z: 0.018300636\n",
       ", x: 0.50972354\n",
       "y: 0.7351286\n",
       "z: 0.117087476\n",
       ", x: 0.6041726\n",
       "y: 0.70319796\n",
       "z: -0.027032165\n",
       ", x: 0.6150942\n",
       "y: 0.70750713\n",
       "z: -0.025528623\n",
       ", x: 0.58550364\n",
       "y: 0.76786757\n",
       "z: 0.01716276\n",
       ", x: 0.5909332\n",
       "y: 0.76662195\n",
       "z: 0.0141803585\n",
       ", x: 0.516268\n",
       "y: 0.54838836\n",
       "z: -0.03112519\n",
       ", x: 0.5941243\n",
       "y: 0.70129704\n",
       "z: -0.025807576\n",
       ", x: 0.56609035\n",
       "y: 0.55777013\n",
       "z: -0.046510685\n",
       ", x: 0.56306225\n",
       "y: 0.54426956\n",
       "z: -0.052018084\n",
       ", x: 0.5455396\n",
       "y: 0.4746618\n",
       "z: -0.0476919\n",
       ", x: 0.5061351\n",
       "y: 0.528559\n",
       "z: -0.018266324\n",
       ", x: 0.55596095\n",
       "y: 0.50879234\n",
       "z: -0.050927803\n",
       ", x: 0.50459504\n",
       "y: 0.5608399\n",
       "z: -0.014026219\n",
       ", x: 0.4951976\n",
       "y: 0.5484273\n",
       "z: 0.005355196\n",
       ", x: 0.62451637\n",
       "y: 0.75937045\n",
       "z: -0.017185276\n",
       ", x: 0.61132336\n",
       "y: 0.76235974\n",
       "z: -0.011083532\n",
       ", x: 0.6014872\n",
       "y: 0.7642256\n",
       "z: -0.0031745625\n",
       ", x: 0.6073786\n",
       "y: 0.70552087\n",
       "z: -0.023608036\n",
       ", x: 0.58851844\n",
       "y: 0.767624\n",
       "z: 0.015575072\n",
       ", x: 0.59402335\n",
       "y: 0.7705985\n",
       "z: 0.010277619\n",
       ", x: 0.59183735\n",
       "y: 0.7652289\n",
       "z: 0.013828358\n",
       ", x: 0.6122694\n",
       "y: 0.6999852\n",
       "z: -0.04478275\n",
       ", x: 0.60691434\n",
       "y: 0.7648783\n",
       "z: 0.0026731112\n",
       ", x: 0.6160873\n",
       "y: 0.7655692\n",
       "z: -0.0021350211\n",
       ", x: 0.62686825\n",
       "y: 0.7658626\n",
       "z: -0.005398271\n",
       ", x: 0.62292796\n",
       "y: 0.80228895\n",
       "z: 0.013917836\n",
       ", x: 0.6243547\n",
       "y: 0.79197884\n",
       "z: -0.00021474167\n",
       ", x: 0.62506527\n",
       "y: 0.78327906\n",
       "z: -0.0033645332\n",
       ", x: 0.6256831\n",
       "y: 0.7743923\n",
       "z: -0.0023148365\n",
       ", x: 0.6262636\n",
       "y: 0.76817524\n",
       "z: -0.0014326476\n",
       ", x: 0.60531425\n",
       "y: 0.7674789\n",
       "z: 0.0051495237\n",
       ", x: 0.6036641\n",
       "y: 0.77001387\n",
       "z: 0.003938778\n",
       ", x: 0.6010858\n",
       "y: 0.7746877\n",
       "z: 0.003519659\n",
       ", x: 0.59873164\n",
       "y: 0.77971685\n",
       "z: 0.0063558775\n",
       ", x: 0.58565605\n",
       "y: 0.7418803\n",
       "z: -0.0047502583\n",
       ", x: 0.49088627\n",
       "y: 0.66090107\n",
       "z: 0.11472685\n",
       ", x: 0.6372965\n",
       "y: 0.7100083\n",
       "z: -0.0359827\n",
       ", x: 0.5990721\n",
       "y: 0.76672786\n",
       "z: 0.010077526\n",
       ", x: 0.5969052\n",
       "y: 0.7683373\n",
       "z: 0.009590981\n",
       ", x: 0.620023\n",
       "y: 0.71435624\n",
       "z: -0.024276685\n",
       ", x: 0.59860957\n",
       "y: 0.7094759\n",
       "z: -0.01453215\n",
       ", x: 0.61762005\n",
       "y: 0.7110984\n",
       "z: -0.025342239\n",
       ", x: 0.5806305\n",
       "y: 0.6503958\n",
       "z: -0.014741065\n",
       ", x: 0.5622772\n",
       "y: 0.66288126\n",
       "z: -0.010768459\n",
       ", x: 0.5909894\n",
       "y: 0.6923678\n",
       "z: -0.023610955\n",
       ", x: 0.5142493\n",
       "y: 0.4889208\n",
       "z: -0.026462838\n",
       ", x: 0.5253001\n",
       "y: 0.5143334\n",
       "z: -0.036388114\n",
       ", x: 0.5362766\n",
       "y: 0.54223675\n",
       "z: -0.043374725\n",
       ", x: 0.59305817\n",
       "y: 0.78861004\n",
       "z: 0.016472094\n",
       ", x: 0.5939377\n",
       "y: 0.5474018\n",
       "z: -0.05489878\n",
       ", x: 0.5876858\n",
       "y: 0.5067766\n",
       "z: -0.057611052\n",
       ", x: 0.5799075\n",
       "y: 0.46620062\n",
       "z: -0.057861153\n",
       ", x: 0.53996223\n",
       "y: 0.6145415\n",
       "z: -0.008961343\n",
       ", x: 0.5127691\n",
       "y: 0.62960905\n",
       "z: 0.009429942\n",
       ", x: 0.5904245\n",
       "y: 0.60480607\n",
       "z: -0.012228277\n",
       ", x: 0.5205364\n",
       "y: 0.58925253\n",
       "z: -0.009865376\n",
       ", x: 0.60050815\n",
       "y: 0.6315059\n",
       "z: -0.02568055\n",
       ", x: 0.60328215\n",
       "y: 0.6917444\n",
       "z: -0.04624331\n",
       ", x: 0.5006392\n",
       "y: 0.6383681\n",
       "z: 0.02399251\n",
       ", x: 0.52285826\n",
       "y: 0.6422492\n",
       "z: 0.0019938038\n",
       ", x: 0.5396885\n",
       "y: 0.6487378\n",
       "z: -0.0061656446\n",
       ", x: 0.5628791\n",
       "y: 0.64426285\n",
       "z: -0.009994583\n",
       ", x: 0.5789662\n",
       "y: 0.63579327\n",
       "z: -0.012316955\n",
       ", x: 0.5905576\n",
       "y: 0.62792265\n",
       "z: -0.016154103\n",
       ", x: 0.6175976\n",
       "y: 0.6127055\n",
       "z: -0.041740797\n",
       ", x: 0.50608534\n",
       "y: 0.6715263\n",
       "z: 0.02810807\n",
       ", x: 0.5100753\n",
       "y: 0.58610183\n",
       "z: -0.006373466\n",
       ", x: 0.6317656\n",
       "y: 0.70880395\n",
       "z: -0.053074617\n",
       ", x: 0.59468836\n",
       "y: 0.6582695\n",
       "z: -0.021314697\n",
       ", x: 0.48195076\n",
       "y: 0.5942106\n",
       "z: 0.087407\n",
       ", x: 0.5995243\n",
       "y: 0.62004125\n",
       "z: -0.019213105\n",
       ", x: 0.5894627\n",
       "y: 0.69145906\n",
       "z: -0.011209687\n",
       ", x: 0.5278916\n",
       "y: 0.59920233\n",
       "z: -0.0032184457\n",
       ", x: 0.6012927\n",
       "y: 0.6802867\n",
       "z: -0.043429375\n",
       ", x: 0.49789774\n",
       "y: 0.69702935\n",
       "z: 0.11893737\n",
       ", x: 0.5889598\n",
       "y: 0.5993619\n",
       "z: -0.0109550385\n",
       ", x: 0.61263853\n",
       "y: 0.6728134\n",
       "z: -0.05601707\n",
       ", x: 0.5409152\n",
       "y: 0.7828455\n",
       "z: 0.06402412\n",
       ", x: 0.54147553\n",
       "y: 0.79258835\n",
       "z: 0.08921748\n",
       ", x: 0.4932487\n",
       "y: 0.6679345\n",
       "z: 0.07063721\n",
       ", x: 0.5244653\n",
       "y: 0.760478\n",
       "z: 0.073030844\n",
       ", x: 0.49044728\n",
       "y: 0.57298934\n",
       "z: 0.029524086\n",
       ", x: 0.59289545\n",
       "y: 0.83405274\n",
       "z: 0.04229606\n",
       ", x: 0.6322527\n",
       "y: 0.7098605\n",
       "z: -0.035544436\n",
       ", x: 0.5845489\n",
       "y: 0.6698528\n",
       "z: -0.015137857\n",
       ", x: 0.49884367\n",
       "y: 0.6077128\n",
       "z: 0.020980923\n",
       ", x: 0.5512949\n",
       "y: 0.60826206\n",
       "z: -0.013158437\n",
       ", x: 0.56258893\n",
       "y: 0.6082303\n",
       "z: -0.015172403\n",
       ", x: 0.59090805\n",
       "y: 0.77331394\n",
       "z: 0.01260158\n",
       ", x: 0.5110384\n",
       "y: 0.700956\n",
       "z: 0.040274072\n",
       ", x: 0.6146988\n",
       "y: 0.85024035\n",
       "z: 0.052340686\n",
       ", x: 0.5776711\n",
       "y: 0.8291101\n",
       "z: 0.06711308\n",
       ", x: 0.5611317\n",
       "y: 0.8142983\n",
       "z: 0.07653405\n",
       ", x: 0.62319803\n",
       "y: 0.50410867\n",
       "z: -0.057235345\n",
       ", x: 0.63893837\n",
       "y: 0.8504216\n",
       "z: 0.05165163\n",
       ", x: 0.5725728\n",
       "y: 0.60568404\n",
       "z: -0.015087067\n",
       ", x: 0.58157694\n",
       "y: 0.60194063\n",
       "z: -0.013277185\n",
       ", x: 0.5868121\n",
       "y: 0.6001869\n",
       "z: -0.0111003965\n",
       ", x: 0.50069714\n",
       "y: 0.5808569\n",
       "z: 0.004014468\n",
       ", x: 0.5774233\n",
       "y: 0.5905076\n",
       "z: -0.017789025\n",
       ", x: 0.56618327\n",
       "y: 0.58777994\n",
       "z: -0.021132104\n",
       ", x: 0.55522823\n",
       "y: 0.5882628\n",
       "z: -0.021392995\n",
       ", x: 0.54449564\n",
       "y: 0.5913292\n",
       "z: -0.018840035\n",
       ", x: 0.5380299\n",
       "y: 0.59510237\n",
       "z: -0.014881673\n",
       ", x: 0.48149216\n",
       "y: 0.5606603\n",
       "z: 0.059360083\n",
       ", x: 0.54316986\n",
       "y: 0.6062271\n",
       "z: -0.010414473\n",
       ", x: 0.63707674\n",
       "y: 0.72490776\n",
       "z: -0.021695962\n",
       ", x: 0.59535706\n",
       "y: 0.7328861\n",
       "z: -0.012054184\n",
       ", x: 0.60424614\n",
       "y: 0.7014698\n",
       "z: -0.032383803\n",
       ", x: 0.6197506\n",
       "y: 0.72809935\n",
       "z: -0.021744998\n",
       ", x: 0.62772906\n",
       "y: 0.58679044\n",
       "z: -0.041785948\n",
       ", x: 0.5581335\n",
       "y: 0.8033112\n",
       "z: 0.058314268\n",
       ", x: 0.57482255\n",
       "y: 0.8186803\n",
       "z: 0.0512663\n",
       ", x: 0.61452985\n",
       "y: 0.8444861\n",
       "z: 0.03482986\n",
       ", x: 0.52486926\n",
       "y: 0.7673777\n",
       "z: 0.10473131\n",
       ", x: 0.58528864\n",
       "y: 0.59581107\n",
       "z: -0.0139767295\n",
       ", x: 0.6109665\n",
       "y: 0.6393028\n",
       "z: -0.040484406\n",
       ", x: 0.63991225\n",
       "y: 0.84455305\n",
       "z: 0.03470677\n",
       ", x: 0.59514976\n",
       "y: 0.8421017\n",
       "z: 0.057307087\n",
       ", x: 0.5000699\n",
       "y: 0.7004813\n",
       "z: 0.07771647\n",
       ", x: 0.61496264\n",
       "y: 0.76802003\n",
       "z: 0.0011889689\n",
       ", x: 0.6134432\n",
       "y: 0.7726586\n",
       "z: -8.8285124e-05\n",
       ", x: 0.61171573\n",
       "y: 0.7794908\n",
       "z: -0.0007626589\n",
       ", x: 0.61035144\n",
       "y: 0.78746307\n",
       "z: 0.0021450196\n",
       ", x: 0.60642755\n",
       "y: 0.7969094\n",
       "z: 0.013503165\n",
       ", x: 0.59679884\n",
       "y: 0.7667761\n",
       "z: 0.0070964047\n",
       ", x: 0.5932782\n",
       "y: 0.766118\n",
       "z: 0.006490991\n",
       ", x: 0.58964443\n",
       "y: 0.76392084\n",
       "z: 0.005664075\n",
       ", x: 0.57724994\n",
       "y: 0.753827\n",
       "z: 0.005423981\n",
       ", x: 0.5286636\n",
       "y: 0.7126649\n",
       "z: 0.019463146\n",
       ", x: 0.6090753\n",
       "y: 0.62120324\n",
       "z: -0.032971457\n",
       ", x: 0.5987539\n",
       "y: 0.589613\n",
       "z: -0.020371055\n",
       ", x: 0.5905585\n",
       "y: 0.59160936\n",
       "z: -0.016673317\n",
       ", x: 0.5990546\n",
       "y: 0.76427376\n",
       "z: 0.008819052\n",
       ", x: 0.5291354\n",
       "y: 0.745162\n",
       "z: 0.04586368\n",
       ", x: 0.6107933\n",
       "y: 0.5899957\n",
       "z: -0.034574687\n",
       ", x: 0.60010684\n",
       "y: 0.80863667\n",
       "z: 0.023307828\n",
       ", x: 0.6338876\n",
       "y: 0.6459738\n",
       "z: -0.058879722\n",
       ", x: 0.620185\n",
       "y: 0.63186485\n",
       "z: -0.050044045\n",
       ", x: 0.6319333\n",
       "y: 0.62780017\n",
       "z: -0.052216277\n",
       ", x: 0.60335225\n",
       "y: 0.664498\n",
       "z: -0.035669785\n",
       ", x: 0.6399645\n",
       "y: 0.83217955\n",
       "z: 0.024285099\n",
       ", x: 0.63938576\n",
       "y: 0.81549394\n",
       "z: 0.019781947\n",
       ", x: 0.61963046\n",
       "y: 0.8162633\n",
       "z: 0.020474808\n",
       ", x: 0.57042766\n",
       "y: 0.783665\n",
       "z: 0.027478913\n",
       ", x: 0.5805294\n",
       "y: 0.70425254\n",
       "z: -0.0071830014\n",
       ", x: 0.5839657\n",
       "y: 0.79782766\n",
       "z: 0.026305674\n",
       ", x: 0.5541665\n",
       "y: 0.7030139\n",
       "z: -0.0039078733\n",
       ", x: 0.5714038\n",
       "y: 0.7207375\n",
       "z: -0.002696643\n",
       ", x: 0.5455115\n",
       "y: 0.72674334\n",
       "z: 0.010091262\n",
       ", x: 0.6161689\n",
       "y: 0.83232576\n",
       "z: 0.02490259\n",
       ", x: 0.59564334\n",
       "y: 0.67191464\n",
       "z: -0.025624825\n",
       ", x: 0.5608208\n",
       "y: 0.7916578\n",
       "z: 0.04102491\n",
       ", x: 0.57768834\n",
       "y: 0.80739534\n",
       "z: 0.038826726\n",
       ", x: 0.55995864\n",
       "y: 0.766548\n",
       "z: 0.023559885\n",
       ", x: 0.51615596\n",
       "y: 0.72516066\n",
       "z: 0.051270105\n",
       ", x: 0.54508704\n",
       "y: 0.7649243\n",
       "z: 0.03484068\n",
       ", x: 0.50918\n",
       "y: 0.73085535\n",
       "z: 0.08114469\n",
       ", x: 0.5636662\n",
       "y: 0.74107295\n",
       "z: 0.0062232753\n",
       ", x: 0.6027461\n",
       "y: 0.6484693\n",
       "z: -0.030292971\n",
       ", x: 0.6081695\n",
       "y: 0.69832957\n",
       "z: -0.04787505\n",
       ", x: 0.5990075\n",
       "y: 0.70090353\n",
       "z: -0.033843808\n",
       ", x: 0.6140345\n",
       "y: 0.68980604\n",
       "z: -0.057417624\n",
       ", x: 0.5881084\n",
       "y: 0.578565\n",
       "z: -0.027688412\n",
       ", x: 0.5672764\n",
       "y: 0.5722006\n",
       "z: -0.0326893\n",
       ", x: 0.54950005\n",
       "y: 0.5714073\n",
       "z: -0.03307804\n",
       ", x: 0.534908\n",
       "y: 0.57351744\n",
       "z: -0.028624594\n",
       ", x: 0.52496505\n",
       "y: 0.57905316\n",
       "z: -0.021308545\n",
       ", x: 0.5199574\n",
       "y: 0.6027185\n",
       "z: 0.0013027494\n",
       ", x: 0.4881786\n",
       "y: 0.63551176\n",
       "z: 0.060011838\n",
       ", x: 0.5324439\n",
       "y: 0.6258979\n",
       "z: -0.0024096195\n",
       ", x: 0.54600376\n",
       "y: 0.63058686\n",
       "z: -0.0077861017\n",
       ", x: 0.56247944\n",
       "y: 0.6290625\n",
       "z: -0.01108529\n",
       ", x: 0.57727396\n",
       "y: 0.6235604\n",
       "z: -0.012420796\n",
       ", x: 0.58819133\n",
       "y: 0.6175509\n",
       "z: -0.013092707\n",
       ", x: 0.5957984\n",
       "y: 0.6126084\n",
       "z: -0.014120763\n",
       ", x: 0.48614687\n",
       "y: 0.6268642\n",
       "z: 0.10451861\n",
       ", x: 0.5991136\n",
       "y: 0.70386636\n",
       "z: -0.027179183\n",
       ", x: 0.6128063\n",
       "y: 0.65559787\n",
       "z: -0.04656088\n",
       ", x: 0.61835504\n",
       "y: 0.70030606\n",
       "z: -0.055978887\n",
       ", x: 0.62481976\n",
       "y: 0.705714\n",
       "z: -0.048862033\n",
       ", x: 0.61787707\n",
       "y: 0.7013545\n",
       "z: -0.049752478\n",
       ", x: 0.60260814\n",
       "y: 0.70767987\n",
       "z: -0.021713326\n",
       ", x: 0.6275917\n",
       "y: 0.7076635\n",
       "z: -0.05160125\n",
       ", x: 0.6279426\n",
       "y: 0.70896447\n",
       "z: -0.036273226\n",
       ", x: 0.59372973\n",
       "y: 0.6005017\n",
       "z: -0.011772698\n",
       ", x: 0.6015713\n",
       "y: 0.6045433\n",
       "z: -0.01727588\n",
       ", x: 0.60627997\n",
       "y: 0.60831314\n",
       "z: -0.024287432\n",
       ", x: 0.5343133\n",
       "y: 0.59755063\n",
       "z: -0.010750096\n",
       ", x: 0.5278411\n",
       "y: 0.591271\n",
       "z: -0.011427479\n",
       ", x: 0.6441222\n",
       "y: 0.64659244\n",
       "z: -0.053302273\n",
       ", x: 0.7084571\n",
       "y: 0.5829093\n",
       "z: 0.008219925\n",
       ", x: 0.6483459\n",
       "y: 0.7034856\n",
       "z: -0.03532452\n",
       ", x: 0.73833656\n",
       "y: 0.5064943\n",
       "z: 0.05294734\n",
       ", x: 0.6744619\n",
       "y: 0.6016928\n",
       "z: -0.0045966776\n",
       ", x: 0.6859793\n",
       "y: 0.6017067\n",
       "z: -0.002515472\n",
       ", x: 0.69723356\n",
       "y: 0.59959096\n",
       "z: 0.0015948276\n",
       ", x: 0.71146035\n",
       "y: 0.5868066\n",
       "z: 0.011705202\n",
       ", x: 0.6652877\n",
       "y: 0.59919435\n",
       "z: -0.005306979\n",
       ", x: 0.6920582\n",
       "y: 0.56448036\n",
       "z: -0.013991634\n",
       ", x: 0.6794639\n",
       "y: 0.56720084\n",
       "z: -0.01575374\n",
       ", x: 0.70326596\n",
       "y: 0.5643383\n",
       "z: -0.008500519\n",
       ", x: 0.71032476\n",
       "y: 0.5671916\n",
       "z: -0.0022988352\n",
       ", x: 0.71940166\n",
       "y: 0.59501934\n",
       "z: 0.01991459\n",
       ", x: 0.67899376\n",
       "y: 0.80947655\n",
       "z: 0.038738754\n",
       ", x: 0.7125145\n",
       "y: 0.5778245\n",
       "z: 0.011668666\n",
       ", x: 0.7434412\n",
       "y: 0.573297\n",
       "z: 0.0738463\n",
       ", x: 0.7302416\n",
       "y: 0.58064556\n",
       "z: 0.03055964\n",
       ", x: 0.68879867\n",
       "y: 0.6685228\n",
       "z: -0.0011003272\n",
       ", x: 0.6531841\n",
       "y: 0.7459123\n",
       "z: -0.017579919\n",
       ", x: 0.65091133\n",
       "y: 0.7614976\n",
       "z: -0.008788365\n",
       ", x: 0.6672619\n",
       "y: 0.7464763\n",
       "z: -0.008078916\n",
       ", x: 0.67527324\n",
       "y: 0.7490435\n",
       "z: 0.0028855326\n",
       ", x: 0.66090333\n",
       "y: 0.7590862\n",
       "z: -0.002810471\n",
       ", x: 0.66825247\n",
       "y: 0.7576252\n",
       "z: 0.0066013117\n",
       ", x: 0.68825006\n",
       "y: 0.76449656\n",
       "z: 0.028937155\n",
       ", x: 0.6483235\n",
       "y: 0.7003059\n",
       "z: -0.05893912\n",
       ", x: 0.6494686\n",
       "y: 0.68597025\n",
       "z: -0.064930476\n",
       ", x: 0.72697246\n",
       "y: 0.5470596\n",
       "z: -0.002147698\n",
       ", x: 0.6643571\n",
       "y: 0.6322425\n",
       "z: -0.01328107\n",
       ", x: 0.67332304\n",
       "y: 0.68561506\n",
       "z: -0.027142998\n",
       ", x: 0.67285854\n",
       "y: 0.6760935\n",
       "z: -0.024751445\n",
       ", x: 0.71851575\n",
       "y: 0.65868455\n",
       "z: 0.016526017\n",
       ", x: 0.6470379\n",
       "y: 0.6651601\n",
       "z: -0.061273437\n",
       ", x: 0.7031809\n",
       "y: 0.54081774\n",
       "z: -0.028939791\n",
       ", x: 0.7178767\n",
       "y: 0.540866\n",
       "z: -0.017160047\n",
       ", x: 0.7310723\n",
       "y: 0.4842018\n",
       "z: 0.022536635\n",
       ", x: 0.65287805\n",
       "y: 0.5631078\n",
       "z: -0.041372497\n",
       ", x: 0.6684454\n",
       "y: 0.5729213\n",
       "z: -0.012393548\n",
       ", x: 0.69596785\n",
       "y: 0.7495114\n",
       "z: 0.029792324\n",
       ", x: 0.7292336\n",
       "y: 0.70609254\n",
       "z: 0.13985972\n",
       ", x: 0.6651385\n",
       "y: 0.6949957\n",
       "z: -0.02196939\n",
       ", x: 0.6557829\n",
       "y: 0.7020383\n",
       "z: -0.022949459\n",
       ", x: 0.6844449\n",
       "y: 0.7537081\n",
       "z: 0.027211651\n",
       ", x: 0.67906696\n",
       "y: 0.75398535\n",
       "z: 0.023012696\n",
       ", x: 0.7231101\n",
       "y: 0.5278291\n",
       "z: -0.013172566\n",
       ", x: 0.67328525\n",
       "y: 0.69077134\n",
       "z: -0.019353835\n",
       ", x: 0.682104\n",
       "y: 0.5471667\n",
       "z: -0.037401084\n",
       ", x: 0.68405545\n",
       "y: 0.5332327\n",
       "z: -0.042532314\n",
       ", x: 0.6896506\n",
       "y: 0.4600104\n",
       "z: -0.03480769\n",
       ", x: 0.72713345\n",
       "y: 0.5055971\n",
       "z: 0.0017806203\n",
       ", x: 0.6857756\n",
       "y: 0.49615946\n",
       "z: -0.039774552\n",
       ", x: 0.7320682\n",
       "y: 0.5366916\n",
       "z: 0.006879887\n",
       ", x: 0.7354809\n",
       "y: 0.52252793\n",
       "z: 0.028082406\n",
       ", x: 0.6525232\n",
       "y: 0.7552772\n",
       "z: -0.014489622\n",
       ", x: 0.6639201\n",
       "y: 0.7545245\n",
       "z: -0.0058216797\n",
       ", x: 0.6719212\n",
       "y: 0.7538496\n",
       "z: 0.003803467\n",
       ", x: 0.6621816\n",
       "y: 0.6981214\n",
       "z: -0.019603146\n",
       ", x: 0.6817182\n",
       "y: 0.7541959\n",
       "z: 0.024822796\n",
       ", x: 0.6776343\n",
       "y: 0.7587178\n",
       "z: 0.018115869\n",
       ", x: 0.67765623\n",
       "y: 0.7528908\n",
       "z: 0.022490952\n",
       ", x: 0.65965074\n",
       "y: 0.69354814\n",
       "z: -0.040206566\n",
       ", x: 0.6652603\n",
       "y: 0.7564915\n",
       "z: 0.008688629\n",
       ", x: 0.657809\n",
       "y: 0.759618\n",
       "z: 0.0023386406\n",
       ", x: 0.64872736\n",
       "y: 0.7627961\n",
       "z: -0.0029584146\n",
       ", x: 0.6539482\n",
       "y: 0.7978733\n",
       "z: 0.016264202\n",
       ", x: 0.6543071\n",
       "y: 0.7878319\n",
       "z: 0.002302032\n",
       ", x: 0.65345025\n",
       "y: 0.7792846\n",
       "z: -0.00067564385\n",
       ", x: 0.65180624\n",
       "y: 0.77076995\n",
       "z: 0.00035877386\n",
       ", x: 0.6501008\n",
       "y: 0.7648343\n",
       "z: 0.0011282313\n",
       ", x: 0.6673252\n",
       "y: 0.7586212\n",
       "z: 0.011255007\n",
       ", x: 0.66940826\n",
       "y: 0.76071405\n",
       "z: 0.01011574\n",
       ", x: 0.67251444\n",
       "y: 0.76462466\n",
       "z: 0.009730359\n",
       ", x: 0.6750602\n",
       "y: 0.769019\n",
       "z: 0.013050332\n",
       ", x: 0.68369925\n",
       "y: 0.7282699\n",
       "z: 0.004119272\n",
       ", x: 0.73765445\n",
       "y: 0.63094646\n",
       "z: 0.14027543\n",
       ", x: 0.67195606\n",
       "y: 0.7563777\n",
       "z: 0.017698139\n",
       ", x: 0.67462367\n",
       "y: 0.7573309\n",
       "z: 0.017278092\n",
       ", x: 0.652058\n",
       "y: 0.71005195\n",
       "z: -0.0218461\n",
       ", x: 0.6692284\n",
       "y: 0.6999821\n",
       "z: -0.009455053\n",
       ", x: 0.6538444\n",
       "y: 0.706256\n",
       "z: -0.02292879\n",
       ", x: 0.67557627\n",
       "y: 0.6385686\n",
       "z: -0.005773961\n",
       ", x: 0.69376975\n",
       "y: 0.6464173\n",
       "z: 0.0011156157\n",
       ", x: 0.67429435\n",
       "y: 0.68132913\n",
       "z: -0.016607028\n",
       ", x: 0.716014\n",
       "y: 0.46809554\n",
       "z: -0.0081271995\n",
       ", x: 0.7114899\n",
       "y: 0.49581677\n",
       "z: -0.020260317\n",
       ", x: 0.7066941\n",
       "y: 0.52606034\n",
       "z: -0.029267864\n",
       ", x: 0.6791918\n",
       "y: 0.7763879\n",
       "z: 0.02430354\n",
       ", x: 0.6563067\n",
       "y: 0.5422485\n",
       "z: -0.050282415\n",
       ", x: 0.65728396\n",
       "y: 0.5000006\n",
       "z: -0.05178392\n",
       ", x: 0.6586985\n",
       "y: 0.45824823\n",
       "z: -0.051389083\n",
       ", x: 0.7065308\n",
       "y: 0.59447426\n",
       "z: 0.0072423858\n",
       ", x: 0.7301287\n",
       "y: 0.6033685\n",
       "z: 0.0297888\n",
       ", x: 0.6599302\n",
       "y: 0.5964844\n",
       "z: -0.0049458225\n",
       ", x: 0.7209531\n",
       "y: 0.5668556\n",
       "z: 0.008885149\n",
       ", x: 0.65655637\n",
       "y: 0.6247223\n",
       "z: -0.020215629\n",
       ", x: 0.6668738\n",
       "y: 0.6834521\n",
       "z: -0.04081486\n",
       ", x: 0.7396442\n",
       "y: 0.609465\n",
       "z: 0.04698626\n",
       ", x: 0.7241359\n",
       "y: 0.61752963\n",
       "z: 0.02108133\n",
       ", x: 0.71121895\n",
       "y: 0.62749493\n",
       "z: 0.009833048\n",
       ", x: 0.6901517\n",
       "y: 0.62852633\n",
       "z: 0.0021172662\n",
       ", x: 0.67450583\n",
       "y: 0.6240712\n",
       "z: -0.00312104\n",
       ", x: 0.6632954\n",
       "y: 0.61908716\n",
       "z: -0.009134322\n",
       ", x: 0.6413841\n",
       "y: 0.60999936\n",
       "z: -0.039492745\n",
       ", x: 0.73873484\n",
       "y: 0.6424143\n",
       "z: 0.050842877\n",
       ", x: 0.7290974\n",
       "y: 0.5616669\n",
       "z: 0.014362948\n",
       ", x: 0.64408165\n",
       "y: 0.70714474\n",
       "z: -0.051908713\n",
       ", x: 0.66524667\n",
       "y: 0.6494671\n",
       "z: -0.014589334\n",
       ", x: 0.7408968\n",
       "y: 0.5648009\n",
       "z: 0.11379047\n",
       ", x: 0.65486956\n",
       "y: 0.61341524\n",
       "z: -0.013725637\n",
       ", x: 0.6740254\n",
       "y: 0.680259\n",
       "z: -0.004423152\n",
       ", x: 0.71510386\n",
       "y: 0.5774469\n",
       "z: 0.014391001\n",
       ", x: 0.66611475\n",
       "y: 0.6720448\n",
       "z: -0.038003594\n",
       ", x: 0.73507416\n",
       "y: 0.6669858\n",
       "z: 0.14341936\n",
       ", x: 0.6603662\n",
       "y: 0.59085196\n",
       "z: -0.0032321604\n",
       ", x: 0.65689945\n",
       "y: 0.66724837\n",
       "z: -0.052113276\n",
       ", x: 0.7163538\n",
       "y: 0.75814414\n",
       "z: 0.08075255\n",
       ", x: 0.71246016\n",
       "y: 0.7682435\n",
       "z: 0.1063684\n",
       ", x: 0.74337673\n",
       "y: 0.63697946\n",
       "z: 0.09574708\n",
       ", x: 0.72643197\n",
       "y: 0.73291475\n",
       "z: 0.09290338\n",
       ", x: 0.7394698\n",
       "y: 0.54514354\n",
       "z: 0.053776097\n",
       ", x: 0.68065304\n",
       "y: 0.82101095\n",
       "z: 0.050160494\n",
       ", x: 0.64216644\n",
       "y: 0.7085979\n",
       "z: -0.034796212\n",
       ", x: 0.67505914\n",
       "y: 0.65831923\n",
       "z: -0.0069934335\n",
       ", x: 0.7375727\n",
       "y: 0.57998264\n",
       "z: 0.04382526\n",
       ", x: 0.6966988\n",
       "y: 0.5907315\n",
       "z: 0.0010481494\n",
       ", x: 0.6862106\n",
       "y: 0.593373\n",
       "z: -0.0026139144\n",
       ", x: 0.6805855\n",
       "y: 0.7605255\n",
       "z: 0.02100956\n",
       ", x: 0.73637545\n",
       "y: 0.6719011\n",
       "z: 0.062120065\n",
       ", x: 0.66149175\n",
       "y: 0.8431928\n",
       "z: 0.05664759\n",
       ", x: 0.689283\n",
       "y: 0.8124639\n",
       "z: 0.07822565\n",
       ", x: 0.70010805\n",
       "y: 0.79385275\n",
       "z: 0.09043881\n",
       ", x: 0.67634064\n",
       "y: 0.5932181\n",
       "z: -0.004451303\n",
       ", x: 0.66745627\n",
       "y: 0.59155875\n",
       "z: -0.0041458025\n",
       ", x: 0.6623816\n",
       "y: 0.5911357\n",
       "z: -0.002836957\n",
       ", x: 0.73509395\n",
       "y: 0.5547394\n",
       "z: 0.026274832\n",
       ", x: 0.6698681\n",
       "y: 0.5801244\n",
       "z: -0.008253369\n",
       ", x: 0.67986596\n",
       "y: 0.57519495\n",
       "z: -0.01019266\n",
       ", x: 0.6904262\n",
       "y: 0.5731177\n",
       "z: -0.0085288985\n",
       ", x: 0.7008389\n",
       "y: 0.57353246\n",
       "z: -0.004241836\n",
       ", x: 0.7069746\n",
       "y: 0.5755944\n",
       "z: 0.00069285167\n",
       ", x: 0.74116564\n",
       "y: 0.53183454\n",
       "z: 0.08542196\n",
       ", x: 0.70368755\n",
       "y: 0.58693695\n",
       "z: 0.0050571808\n",
       ", x: 0.6748566\n",
       "y: 0.7219044\n",
       "z: -0.0052115023\n",
       ", x: 0.66561323\n",
       "y: 0.6932242\n",
       "z: -0.027674071\n",
       ", x: 0.6535802\n",
       "y: 0.7233386\n",
       "z: -0.01884424\n",
       ", x: 0.7048645\n",
       "y: 0.78194046\n",
       "z: 0.07191018\n",
       ", x: 0.693171\n",
       "y: 0.80116826\n",
       "z: 0.06206608\n",
       ", x: 0.66336644\n",
       "y: 0.8372425\n",
       "z: 0.039055187\n",
       ", x: 0.72149795\n",
       "y: 0.7404764\n",
       "z: 0.12516667\n",
       ", x: 0.66343206\n",
       "y: 0.5866526\n",
       "z: -0.0054802024\n",
       ", x: 0.6509921\n",
       "y: 0.6345045\n",
       "z: -0.03674139\n",
       ", x: 0.67725766\n",
       "y: 0.8297675\n",
       "z: 0.06539426\n",
       ", x: 0.73996365\n",
       "y: 0.66975236\n",
       "z: 0.10168021\n",
       ", x: 0.65969086\n",
       "y: 0.76164496\n",
       "z: 0.0057479213\n",
       ", x: 0.6619406\n",
       "y: 0.76580554\n",
       "z: 0.004640116\n",
       ", x: 0.6643885\n",
       "y: 0.7720717\n",
       "z: 0.0040607746\n",
       ", x: 0.666212\n",
       "y: 0.7795907\n",
       "z: 0.0071589695\n",
       ", x: 0.6682444\n",
       "y: 0.7881457\n",
       "z: 0.019057658\n",
       ", x: 0.6746043\n",
       "y: 0.75551146\n",
       "z: 0.015121194\n",
       ", x: 0.6781155\n",
       "y: 0.7538103\n",
       "z: 0.01520319\n",
       ", x: 0.6813834\n",
       "y: 0.750688\n",
       "z: 0.014962226\n",
       ", x: 0.69135803\n",
       "y: 0.73796654\n",
       "z: 0.016288172\n",
       ", x: 0.7254462\n",
       "y: 0.68701094\n",
       "z: 0.037685867\n",
       ", x: 0.6488616\n",
       "y: 0.6165556\n",
       "z: -0.029142397\n",
       ", x: 0.65190667\n",
       "y: 0.58387834\n",
       "z: -0.015203681\n",
       ", x: 0.6586193\n",
       "y: 0.58400947\n",
       "z: -0.009530501\n",
       ", x: 0.67152566\n",
       "y: 0.7538787\n",
       "z: 0.016402949\n",
       ", x: 0.72525716\n",
       "y: 0.71879834\n",
       "z: 0.064420134\n",
       ", x: 0.6430015\n",
       "y: 0.58674145\n",
       "z: -0.031567656\n",
       ", x: 0.67358965\n",
       "y: 0.7979324\n",
       "z: 0.029491689\n",
       ", x: 0.64306754\n",
       "y: 0.6291891\n",
       "z: -0.048017055\n",
       ", x: 0.6606041\n",
       "y: 0.65732616\n",
       "z: -0.030671084\n",
       ", x: 0.6575329\n",
       "y: 0.8107608\n",
       "z: 0.02335326\n",
       ", x: 0.69718164\n",
       "y: 0.7657144\n",
       "z: 0.038375687\n",
       ", x: 0.6833543\n",
       "y: 0.69064903\n",
       "z: 0.0014120314\n",
       ", x: 0.6864929\n",
       "y: 0.78304434\n",
       "z: 0.034948196\n",
       ", x: 0.7058507\n",
       "y: 0.6833661\n",
       "z: 0.009079913\n",
       ", x: 0.69309556\n",
       "y: 0.70460033\n",
       "z: 0.0078788875\n",
       ", x: 0.71436346\n",
       "y: 0.7044143\n",
       "z: 0.024910998\n",
       ", x: 0.6618934\n",
       "y: 0.82566893\n",
       "z: 0.028882556\n",
       ", x: 0.66695106\n",
       "y: 0.662783\n",
       "z: -0.019391725\n",
       ", x: 0.7042983\n",
       "y: 0.77111334\n",
       "z: 0.053749144\n",
       ", x: 0.6916783\n",
       "y: 0.7907627\n",
       "z: 0.04857927\n",
       ", x: 0.7052568\n",
       "y: 0.7463603\n",
       "z: 0.036840286\n",
       ", x: 0.73316646\n",
       "y: 0.6966428\n",
       "z: 0.07216042\n",
       ", x: 0.7155103\n",
       "y: 0.74136513\n",
       "z: 0.05032907\n",
       ", x: 0.7350869\n",
       "y: 0.7010451\n",
       "z: 0.10390037\n",
       ", x: 0.7012075\n",
       "y: 0.7225538\n",
       "z: 0.018657241\n",
       ", x: 0.6580547\n",
       "y: 0.64169556\n",
       "z: -0.024923194\n",
       ", x: 0.6635072\n",
       "y: 0.6909696\n",
       "z: -0.04300788\n",
       ", x: 0.6703182\n",
       "y: 0.69141227\n",
       "z: -0.028204722\n",
       ", x: 0.65889025\n",
       "y: 0.6840375\n",
       "z: -0.053418767\n",
       ", x: 0.6612358\n",
       "y: 0.5710945\n",
       "z: -0.02060517\n",
       ", x: 0.6802334\n",
       "y: 0.560729\n",
       "z: -0.022720704\n",
       ", x: 0.6965171\n",
       "y: 0.5564079\n",
       "z: -0.020295283\n",
       ", x: 0.7095193\n",
       "y: 0.5553168\n",
       "z: -0.013104634\n",
       ", x: 0.7177994\n",
       "y: 0.5583678\n",
       "z: -0.0037447235\n",
       ", x: 0.7215349\n",
       "y: 0.5792806\n",
       "z: 0.020184724\n",
       ", x: 0.7448281\n",
       "y: 0.6049101\n",
       "z: 0.085715465\n",
       ", x: 0.714038\n",
       "y: 0.6038533\n",
       "z: 0.014785005\n",
       ", x: 0.7031316\n",
       "y: 0.6113887\n",
       "z: 0.007116223\n",
       ", x: 0.68818533\n",
       "y: 0.61372954\n",
       "z: 0.0011274975\n",
       ", x: 0.6739779\n",
       "y: 0.61177945\n",
       "z: -0.0027768693\n",
       ", x: 0.6635261\n",
       "y: 0.60845685\n",
       "z: -0.0058043846\n",
       ", x: 0.65634453\n",
       "y: 0.6053228\n",
       "z: -0.008140089\n",
       ", x: 0.738774\n",
       "y: 0.5972362\n",
       "z: 0.13081147\n",
       ", x: 0.66958416\n",
       "y: 0.6944844\n",
       "z: -0.021673355\n",
       ", x: 0.652983\n",
       "y: 0.65067923\n",
       "z: -0.04263492\n",
       ", x: 0.6561338\n",
       "y: 0.695372\n",
       "z: -0.05284171\n",
       ", x: 0.6492748\n",
       "y: 0.70241386\n",
       "z: -0.047054194\n",
       ", x: 0.65550125\n",
       "y: 0.6962265\n",
       "z: -0.04658136\n",
       ", x: 0.6661928\n",
       "y: 0.69920367\n",
       "z: -0.017103717\n",
       ", x: 0.6475416\n",
       "y: 0.70500636\n",
       "z: -0.050145358\n",
       ", x: 0.64586484\n",
       "y: 0.7066072\n",
       "z: -0.035080098\n",
       ", x: 0.6565421\n",
       "y: 0.59311867\n",
       "z: -0.0054258653\n",
       ", x: 0.65053993\n",
       "y: 0.5988684\n",
       "z: -0.01254956\n",
       ", x: 0.64804983\n",
       "y: 0.6035733\n",
       "z: -0.020419348\n",
       ", x: 0.7102838\n",
       "y: 0.5770372\n",
       "z: 0.0055053304\n",
       ", x: 0.7150936\n",
       "y: 0.57021654\n",
       "z: 0.005981102\n",
       "]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.face_landmarks.landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c93a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results.face_landmarks.landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1e4218",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results.pose_landmarks.landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aae56fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2930d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a470ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_coords = len(results.pose_landmarks.landmark)+len(results.face_landmarks.landmark)\n",
    "num_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55ca2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, num_coords+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f59b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e69352",
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d606aa",
   "metadata": {},
   "source": [
    "# Code for dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0458545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('rdata.csv', mode='w', newline='') as f:\n",
    "#     csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#     csv_writer.writerow(landmarks)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91a7e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_name = \"distracted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e810765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "# # Initiate holistic model\n",
    "# with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "        \n",
    "#         # Recolor Feed\n",
    "#         image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         image.flags.writeable = False        \n",
    "        \n",
    "        \n",
    "#         # Make Detections\n",
    "#         results = holistic.process(image)\n",
    "#         # print(results.face_landmarks)\n",
    "        \n",
    "#         # face_landmarks, pose_landmarks, left_hand_landmarks, right_hand_landmarks\n",
    "        \n",
    "#         # Recolor image back to BGR for rendering\n",
    "#         image.flags.writeable = True   \n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "#         # 1. Draw face landmarks\n",
    "#         mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
    "#                                  mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "#                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "#                                  )\n",
    "        \n",
    "#         # 2. Right hand\n",
    "#         mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "#                                  mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "#                                  mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "#                                  )\n",
    "#  # 3. Left Hand\n",
    "#         mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "#                                  mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "#                                  mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "#                                  )\n",
    "\n",
    "#         # 4. Pose Detections\n",
    "#         mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "#                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "#                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "#                                  )\n",
    "#         # Export coordinates\n",
    "#         try:\n",
    "#             # Extract Pose landmarks\n",
    "#             pose = results.pose_landmarks.landmark\n",
    "#             pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "            \n",
    "#             # Extract Face landmarks\n",
    "#             face = results.face_landmarks.landmark\n",
    "#             face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "            \n",
    "#             # Concate rows\n",
    "#             row = pose_row+face_row\n",
    "            \n",
    "#             # Append class name \n",
    "#             row.insert(0, class_name)\n",
    "            \n",
    "#             # Export to CSV\n",
    "#             with open('rdata.csv', mode='a', newline='') as f:\n",
    "#                 csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "#                 csv_writer.writerow(row) \n",
    "#         except:\n",
    "#             pass\n",
    "                        \n",
    "#             cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "#             if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#                 break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b3f894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c66aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5753f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# row\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a07358",
   "metadata": {},
   "source": [
    "# Data cleaning and preprocessing for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7664db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1223771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('seconddata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30223249",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8665c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894aaaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65423f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc11ebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "n_components = 500  # Adjust this value as needed\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6be64f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd1bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "    'svm':make_pipeline(StandardScaler(),SVC(kernel='rbf')),\n",
    "    'nb':make_pipeline(StandardScaler(), GaussianNB())\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c742a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models = {}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train_pca, y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0917cccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c16c8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859a2227",
   "metadata": {},
   "source": [
    "# VOTING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9ff95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.base import is_classifier\n",
    "\n",
    "# Check if all models are classifiers\n",
    "for name, model in pipelines.items():\n",
    "    if not is_classifier(model):\n",
    "        raise ValueError(f\"The model '{name}' is not a classifier.\")\n",
    "\n",
    "# Assuming fit_models contains the fitted models\n",
    "models = [\n",
    "    ('lr', pipelines['lr']),\n",
    "    ('rc', pipelines['rc']),\n",
    "    ('rf', pipelines['rf']),\n",
    "    ('gb', pipelines['gb']),\n",
    "    ('svm', pipelines['svm']),\n",
    "    ('nb', pipelines['nb'])\n",
    "]\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf = VotingClassifier(estimators=models, voting='hard')\n",
    "\n",
    "# Fit the voting classifier on the training data\n",
    "voting_clf.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict using the ensemble model\n",
    "ensemble_predictions = voting_clf.predict(X_test_pca)\n",
    "\n",
    "ensemble_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c855ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, ensemble_predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4cd37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3153d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('en_model.pkl', 'wb') as f:\n",
    "    pickle.dump(voting_clf,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c10d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# # Load the pre-trained model\n",
    "with open('en_model.pkl', 'rb') as f:\n",
    "    voting_clf = pickle.load(f)\n",
    "\n",
    "# # Initialize MediaPipe Holistic\n",
    "# mp_holistic = mp.solutions.holistic\n",
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Start capturing video from the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to retrieve frame from the webcam.\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame from BGR to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "\n",
    "    # Process the frame with MediaPipe Holistic\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        results = holistic.process(image)\n",
    "\n",
    "    # Convert the frame back from RGB to BGR\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Draw landmarks on the frame\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                               mp_drawing.DrawingSpec(color=(80, 110, 10), thickness=1, circle_radius=1),\n",
    "                               mp_drawing.DrawingSpec(color=(80, 256, 121), thickness=1, circle_radius=1))\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                               mp_drawing.DrawingSpec(color=(80, 22, 10), thickness=2, circle_radius=4),\n",
    "                               mp_drawing.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2))\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                               mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                               mp_drawing.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=2))\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                               mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                               mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "    try:\n",
    "        pose = results.pose_landmarks.landmark\n",
    "        pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "\n",
    "        face = results.face_landmarks.landmark\n",
    "        face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "\n",
    "        row = pose_row + face_row\n",
    "\n",
    "        X = pd.DataFrame([row])\n",
    "        body_language_class = voting_clf.predict(X)[0]\n",
    "        #body_language_prob = voting_clf.predict_proba(X)[0]\n",
    "        print(body_language_class)\n",
    "\n",
    "        # Display the classification result on the frame\n",
    "        cv2.putText(image, body_language_class, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        coordinates = tuple(np.multiply(\n",
    "                            np.array(\n",
    "                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x,\n",
    "                                 results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
    "                        , [640,480]).astype(int))\n",
    "\n",
    "        cv2.rectangle(image,\n",
    "                          (coordinates[0], coordinates[1]+5),\n",
    "                          (coordinates[0]+len(body_language_class)*20, coordinates[1]-30),\n",
    "                          (245, 117, 16), -1)\n",
    "        cv2.putText(image, body_language_class, coordinates,\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "        cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "\n",
    "\n",
    "        cv2.putText(image, 'CLASS'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, body_language_class.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred during prediction:\", e)\n",
    "\n",
    "    # Display the annotated frame\n",
    "    cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "    # Check for 'q' key press to exit\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b6c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = X_train.shape[1]\n",
    "print(\"Number of columns in X_train:\", num_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921b5e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = X_train_pca.shape[1]\n",
    "print(\"Number of columns in X_train:\", num_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ca801c",
   "metadata": {},
   "source": [
    "# STACKING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71842968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "# Load your dataset (assuming you've already loaded and preprocessed it)\n",
    "df = pd.read_csv('seconddata.csv')\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "#PCA\n",
    "from sklearn.decomposition import PCA\n",
    "n_components = 500  # Adjust this value as needed\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('rf', make_pipeline(StandardScaler(), RandomForestClassifier())),\n",
    "    ('gb', make_pipeline(StandardScaler(), GradientBoostingClassifier())),\n",
    "    ('svm', make_pipeline(StandardScaler(), SVC())),\n",
    "    ('mlp', make_pipeline(StandardScaler(), MLPClassifier()))\n",
    "]\n",
    "\n",
    "# Define meta-classifier\n",
    "meta_classifier = RandomForestClassifier()  # You can change this to any classifier you want\n",
    "\n",
    "# Create the stacking classifier\n",
    "stacking_classifier = StackingClassifier(estimators=base_models, final_estimator=meta_classifier)\n",
    "\n",
    "# Train the stacking classifier\n",
    "stacking_classifier.fit(X_train_pca, y_train)\n",
    "\n",
    "# Evaluate the stacking classifier\n",
    "y_pred = stacking_classifier.predict(X_test_pca)\n",
    "\n",
    "\n",
    "# Save the trained model\n",
    "with open('stacking_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(stacking_classifier, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb327ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stacking_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(stacking_classifier, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63434c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# # Load the pre-trained model\n",
    "\n",
    "with open('stacking_classifier.pkl', 'rb') as f:\n",
    "     clf = pickle.load(f)\n",
    "\n",
    "# # Initialize MediaPipe Holistic\n",
    "# mp_holistic = mp.solutions.holistic\n",
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Start capturing video from the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to retrieve frame from the webcam.\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame from BGR to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "\n",
    "    # Process the frame with MediaPipe Holistic\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        results = holistic.process(image)\n",
    "\n",
    "    # Convert the frame back from RGB to BGR\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Draw landmarks on the frame\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                               mp_drawing.DrawingSpec(color=(80, 110, 10), thickness=1, circle_radius=1),\n",
    "                               mp_drawing.DrawingSpec(color=(80, 256, 121), thickness=1, circle_radius=1))\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                               mp_drawing.DrawingSpec(color=(80, 22, 10), thickness=2, circle_radius=4),\n",
    "                               mp_drawing.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2))\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                               mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                               mp_drawing.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=2))\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                               mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                               mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "    try:\n",
    "        pose = results.pose_landmarks.landmark\n",
    "        pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "\n",
    "        face = results.face_landmarks.landmark\n",
    "        face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "\n",
    "        row = pose_row + face_row\n",
    "\n",
    "        X = pd.DataFrame([row])\n",
    "        body_language_class =clf.predict(X)[0]\n",
    "        #body_language_prob = voting_clf.predict_proba(X)[0]\n",
    "        print(body_language_class)\n",
    "\n",
    "        # Display the classification result on the frame\n",
    "        cv2.putText(image, body_language_class, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        coordinates = tuple(np.multiply(\n",
    "                            np.array(\n",
    "                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x,\n",
    "                                 results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
    "                        , [640,480]).astype(int))\n",
    "\n",
    "        cv2.rectangle(image,\n",
    "                          (coordinates[0], coordinates[1]+5),\n",
    "                          (coordinates[0]+len(body_language_class)*20, coordinates[1]-30),\n",
    "                          (245, 117, 16), -1)\n",
    "        cv2.putText(image, body_language_class, coordinates,\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "        cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "\n",
    "\n",
    "        cv2.putText(image, 'CLASS'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, body_language_class.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred during prediction:\", e)\n",
    "\n",
    "    # Display the annotated frame\n",
    "    cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "    # Check for 'q' key press to exit\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e27872",
   "metadata": {},
   "source": [
    "# RESNET50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a181352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Load your dataset (assuming you've already loaded and preprocessed it)\n",
    "df = pd.read_csv('seconddata.csv')\n",
    "\n",
    "# Extract features (X) and labels (y)\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Convert labels to numerical format\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Define input shape based on the number of features\n",
    "input_shape = (X_train.shape[1],)  # Assuming input shape based on the number of features\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=input_shape),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')  # Output layer with softmax activation for multi-class classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train_encoded, validation_data=(X_test, y_test_encoded), epochs=50, batch_size=32, callbacks=callbacks)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test_encoded)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('fully_connected_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bf97ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('fully_connected_model.h5')\n",
    "\n",
    "# Initialize MediaPipe Holistic\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Start capturing video from the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to retrieve frame from the webcam.\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame from BGR to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame with MediaPipe Holistic\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        results = holistic.process(image)\n",
    "\n",
    "    # Convert the frame back from RGB to BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    try:\n",
    "        pose = results.pose_landmarks.landmark\n",
    "        pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "\n",
    "        face = results.face_landmarks.landmark\n",
    "        face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "\n",
    "        row = pose_row + face_row\n",
    "\n",
    "        X = pd.DataFrame([row])\n",
    "        predictions = model.predict(X)\n",
    "        predicted_class_index = np.argmax(predictions)\n",
    "        class_labels_dict = {0: 'active', 1: 'distracted'}  # Replace with your actual class labels\n",
    "        predicted_class_label = class_labels_dict.get(predicted_class_index, 'Unknown')\n",
    "        predicted_class_label_str = str(predicted_class_label)\n",
    "\n",
    "        # Display the predicted class label on the frame\n",
    "        cv2.putText(image, predicted_class_label_str, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        coordinates = tuple(np.multiply(\n",
    "                            np.array(\n",
    "                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x,\n",
    "                                 results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
    "                        , [640,480]).astype(int))\n",
    "\n",
    "        cv2.rectangle(image,\n",
    "                          (coordinates[0], coordinates[1]+5),\n",
    "                          (coordinates[0]+len(predicted_class_label_str)*20, coordinates[1]-30),\n",
    "                          (245, 117, 16), -1)\n",
    "        cv2.putText(image, predicted_class_label_str, coordinates,\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "        cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "\n",
    "\n",
    "        cv2.putText(image, 'CLASS'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, predicted_class_label_str.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred during prediction:\", e)\n",
    "\n",
    "    # Display the annotated frame\n",
    "    cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "    # Check for 'q' key press to exit\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5b31de",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf60be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('seconddata.csv')\n",
    "\n",
    "# Extract features (X) and labels (y)\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "# Convert labels to numerical format\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=1)\n",
    "\n",
    "# Scale the input features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the model architecture with dropout layers\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train, validation_data=(X_test_scaled, y_test), epochs=50, batch_size=32, callbacks=callbacks)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('fully_connected_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f36853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('fully_connected_model.h5')\n",
    "\n",
    "# Initialize MediaPipe Holistic\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Start capturing video from the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to retrieve frame from the webcam.\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame from BGR to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Process the frame with MediaPipe Holistic\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        results = holistic.process(image)\n",
    "\n",
    "    # Convert the frame back from RGB to BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "     # Draw landmarks on the frame\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                                   mp_drawing.DrawingSpec(color=(80, 110, 10), thickness=1, circle_radius=1),\n",
    "                                   mp_drawing.DrawingSpec(color=(80, 256, 121), thickness=1, circle_radius=1))\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                   mp_drawing.DrawingSpec(color=(80, 22, 10), thickness=2, circle_radius=4),\n",
    "                                   mp_drawing.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2))\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                                   mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                                   mp_drawing.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=2))\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                                   mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                                   mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "        \n",
    "    try:\n",
    "        pose = results.pose_landmarks.landmark\n",
    "        pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "\n",
    "        face = results.face_landmarks.landmark\n",
    "        face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "\n",
    "        row = pose_row + face_row\n",
    "\n",
    "        X = pd.DataFrame([row])\n",
    "        predictions = model.predict(X)\n",
    "        predicted_class_index = np.argmax(predictions)\n",
    "        class_labels_dict = {0: 'distracted', 1: 'active'}  # Replace with your actual class labels\n",
    "        predicted_class_label = class_labels_dict.get(predicted_class_index, 'Unknown')\n",
    "        predicted_class_label_str = str(predicted_class_label)\n",
    "\n",
    "        # Display the predicted class label on the frame\n",
    "        cv2.putText(image, predicted_class_label_str, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        coordinates = tuple(np.multiply(\n",
    "                            np.array(\n",
    "                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x,\n",
    "                                 results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
    "                        , [640,480]).astype(int))\n",
    "\n",
    "        cv2.rectangle(image,\n",
    "                          (coordinates[0], coordinates[1]+5),\n",
    "                          (coordinates[0]+len(predicted_class_label_str)*20, coordinates[1]-30),\n",
    "                          (245, 117, 16), -1)\n",
    "        cv2.putText(image, predicted_class_label_str, coordinates,\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "        cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "\n",
    "\n",
    "        cv2.putText(image, 'CLASS'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, predicted_class_label_str.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred during prediction:\", e)\n",
    "\n",
    "    # Display the annotated frame\n",
    "    cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "    # Check for 'q' key press to exit\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611e509c",
   "metadata": {},
   "source": [
    "# ADABOOST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e308b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"seconddata.csv\")\n",
    "\n",
    "# Split features and target variable\n",
    "X = data.drop(columns=['class'])  # Assuming 'target_column' is the name of the target column\n",
    "y = data['class']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize AdaBoost classifier\n",
    "ada_clf = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred = ada_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e22c938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# # Load the pre-trained model\n",
    "with open('ensemble_model.pkl', 'rb') as f:\n",
    "    voting_clf = pickle.load(f)\n",
    "\n",
    "# # Initialize MediaPipe Holistic\n",
    "# mp_holistic = mp.solutions.holistic\n",
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Start capturing video from the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to retrieve frame from the webcam.\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame from BGR to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "\n",
    "    # Process the frame with MediaPipe Holistic\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        results = holistic.process(image)\n",
    "\n",
    "    # Convert the frame back from RGB to BGR\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Draw landmarks on the frame\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                               mp_drawing.DrawingSpec(color=(80, 110, 10), thickness=1, circle_radius=1),\n",
    "                               mp_drawing.DrawingSpec(color=(80, 256, 121), thickness=1, circle_radius=1))\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                               mp_drawing.DrawingSpec(color=(80, 22, 10), thickness=2, circle_radius=4),\n",
    "                               mp_drawing.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2))\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                               mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                               mp_drawing.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=2))\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                               mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                               mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "    try:\n",
    "        pose = results.pose_landmarks.landmark\n",
    "        pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "\n",
    "        face = results.face_landmarks.landmark\n",
    "        face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "\n",
    "        row = pose_row + face_row\n",
    "\n",
    "        X = pd.DataFrame([row])\n",
    "        body_language_class = ada_clf.predict(X)\n",
    "        body_language_str = str(body_language_class[0])  # Convert numpy array to string\n",
    "\n",
    "        print(body_language_str)\n",
    "\n",
    "        # Display the classification result on the frame\n",
    "        cv2.putText(image, body_language_str, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        coordinates = tuple(np.multiply(\n",
    "                            np.array(\n",
    "                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x,\n",
    "                                 results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
    "                        , [640,480]).astype(int))\n",
    "\n",
    "        cv2.rectangle(image,\n",
    "                          (coordinates[0], coordinates[1]+5),\n",
    "                          (coordinates[0]+len(body_language_str)*20, coordinates[1]-30),\n",
    "                          (245, 117, 16), -1)\n",
    "        cv2.putText(image, body_language_str, coordinates,\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "        cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "\n",
    "\n",
    "        cv2.putText(image, 'CLASS'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, body_language_str.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred during prediction:\", e)\n",
    "\n",
    "    # Display the annotated frame\n",
    "    cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "    # Check for 'q' key press to exit\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "for i in range(1,5):\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f29cd4",
   "metadata": {},
   "source": [
    "# LINEAR SUPPORT VECTOR CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53f3eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"seconddata.csv\")\n",
    "\n",
    "# Assuming 'target_column' is the name of the target column\n",
    "X = data.drop(columns=['class'])\n",
    "y = data['class']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Linear Support Vector Classifier (LinearSVC)\n",
    "ls_clf = LinearSVC(random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "ls_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred = ls_clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb965f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# # Load the pre-trained model\n",
    "with open('ensemble_model.pkl', 'rb') as f:\n",
    "    voting_clf = pickle.load(f)\n",
    "\n",
    "# # Initialize MediaPipe Holistic\n",
    "# mp_holistic = mp.solutions.holistic\n",
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Start capturing video from the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to retrieve frame from the webcam.\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame from BGR to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "\n",
    "    # Process the frame with MediaPipe Holistic\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        results = holistic.process(image)\n",
    "\n",
    "    # Convert the frame back from RGB to BGR\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Draw landmarks on the frame\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                               mp_drawing.DrawingSpec(color=(80, 110, 10), thickness=1, circle_radius=1),\n",
    "                               mp_drawing.DrawingSpec(color=(80, 256, 121), thickness=1, circle_radius=1))\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                               mp_drawing.DrawingSpec(color=(80, 22, 10), thickness=2, circle_radius=4),\n",
    "                               mp_drawing.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2))\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                               mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                               mp_drawing.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=2))\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                               mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                               mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "    try:\n",
    "        pose = results.pose_landmarks.landmark\n",
    "        pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "\n",
    "        face = results.face_landmarks.landmark\n",
    "        face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "\n",
    "        row = pose_row + face_row\n",
    "\n",
    "        X = pd.DataFrame([row])\n",
    "        body_language_class = ls_clf.predict(X)\n",
    "        body_language_str = str(body_language_class[0])  # Convert numpy array to string\n",
    "\n",
    "        print(body_language_str)\n",
    "\n",
    "        # Display the classification result on the frame\n",
    "        cv2.putText(image, body_language_str, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        coordinates = tuple(np.multiply(\n",
    "                            np.array(\n",
    "                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x,\n",
    "                                 results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
    "                        , [640,480]).astype(int))\n",
    "\n",
    "        cv2.rectangle(image,\n",
    "                          (coordinates[0], coordinates[1]+5),\n",
    "                          (coordinates[0]+len(body_language_str)*20, coordinates[1]-30),\n",
    "                          (245, 117, 16), -1)\n",
    "        cv2.putText(image, body_language_str, coordinates,\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "        cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "\n",
    "\n",
    "        cv2.putText(image, 'CLASS'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, body_language_str.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred during prediction:\", e)\n",
    "\n",
    "    # Display the annotated frame\n",
    "    cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "    # Check for 'q' key press to exit\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "for i in range(1,5):\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca8573e",
   "metadata": {},
   "source": [
    "# MLP CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecd0b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"seconddata.csv\")\n",
    "\n",
    "# Assuming 'target_column' is the name of the target column\n",
    "X = data.drop(columns=['class'])\n",
    "y = data['class']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Multi-layer Perceptron Classifier (MLPClassifier)\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d69e576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# # Load the pre-trained model\n",
    "with open('ensemble_model.pkl', 'rb') as f:\n",
    "    voting_clf = pickle.load(f)\n",
    "\n",
    "# # Initialize MediaPipe Holistic\n",
    "# mp_holistic = mp.solutions.holistic\n",
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Start capturing video from the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        print(\"Failed to retrieve frame from the webcam.\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame from BGR to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "\n",
    "    # Process the frame with MediaPipe Holistic\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        results = holistic.process(image)\n",
    "\n",
    "    # Convert the frame back from RGB to BGR\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Draw landmarks on the frame\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                               mp_drawing.DrawingSpec(color=(80, 110, 10), thickness=1, circle_radius=1),\n",
    "                               mp_drawing.DrawingSpec(color=(80, 256, 121), thickness=1, circle_radius=1))\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                               mp_drawing.DrawingSpec(color=(80, 22, 10), thickness=2, circle_radius=4),\n",
    "                               mp_drawing.DrawingSpec(color=(80, 44, 121), thickness=2, circle_radius=2))\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                               mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                               mp_drawing.DrawingSpec(color=(121, 44, 250), thickness=2, circle_radius=2))\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                               mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=4),\n",
    "                               mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "    try:\n",
    "        pose = results.pose_landmarks.landmark\n",
    "        pose_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]).flatten())\n",
    "\n",
    "        face = results.face_landmarks.landmark\n",
    "        face_row = list(np.array([[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]).flatten())\n",
    "\n",
    "        row = pose_row + face_row\n",
    "\n",
    "        X = pd.DataFrame([row])\n",
    "        body_language_class = mlp.predict(X)\n",
    "        body_language_str = str(body_language_class[0])  # Convert numpy array to string\n",
    "\n",
    "        print(body_language_str)\n",
    "\n",
    "        # Display the classification result on the frame\n",
    "        cv2.putText(image, body_language_str, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        coordinates = tuple(np.multiply(\n",
    "                            np.array(\n",
    "                                (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x,\n",
    "                                 results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y))\n",
    "                        , [640,480]).astype(int))\n",
    "\n",
    "        cv2.rectangle(image,\n",
    "                          (coordinates[0], coordinates[1]+5),\n",
    "                          (coordinates[0]+len(body_language_str)*20, coordinates[1]-30),\n",
    "                          (245, 117, 16), -1)\n",
    "        cv2.putText(image, body_language_str, coordinates,\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "        cv2.rectangle(image, (0,0), (250, 60), (245, 117, 16), -1)\n",
    "\n",
    "\n",
    "        cv2.putText(image, 'CLASS'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(image, body_language_str.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred during prediction:\", e)\n",
    "\n",
    "    # Display the annotated frame\n",
    "    cv2.imshow('Raw Webcam Feed', image)\n",
    "\n",
    "    # Check for 'q' key press to exit\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "for i in range(1,5):\n",
    "    cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
